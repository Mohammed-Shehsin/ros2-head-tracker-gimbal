# ğŸ¤– ROS2 Head Tracker Gimbal  
Dual-Servo Panâ€“Tilt System Controlled by Head Direction Tracking (OpenCV + Mediapipe)

This repository contains the complete implementation of a **2-DOF dual-servo gimbal** that can be controlled in real time using **head direction tracking** from a webcam or external vision system.  
The project supports:

- Real-time head yaw/pitch detection  
- UDP communication between Python â†’ Arduino  
- Servo-based panâ€“tilt control  
- ROS2 URDF/Xacro full model of the physical gimbal  
- RViz2 visualization  
- ROS2-ready package structure  

---

## ğŸ–¼ï¸ System Overview

### Physical Gimbal  
A dual-servo aluminium gimbal made of:
- Base plate  
- Yaw servo (bottom)
- Vertical column
- Pitch servo (upper)
- Camera plate mount  

### ROS2 Model  
âœ” Fully built URDF/Xacro  
âœ” Two revolute joints: `yaw_joint`, `pitch_joint`  
âœ” Visualized in RViz2  
âœ” Dimensions based on real hardware

---

## ğŸ¥ Demo (GIF)  
(Add your GIF here)

```
![demo](media/head_tracker_demo.gif)
```

---

# ğŸš€ Features

### ğŸ”¹ **1. Head Tracking (OpenCV + Mediapipe)**
- Face detection
- Landmark extraction (eyes, nose)
- Direction vectors
- Continuous yaw & pitch score  
- Roll compensation

### ğŸ”¹ **2. 2-Servo Panâ€“Tilt Control**
- Servo1 = Yaw (leftâ€“right)
- Servo2 = Pitch (upâ€“down)
- 90Â° center mapping
- Direction-to-servo mapping with smoothing & sensitivity tuning

### ğŸ”¹ **3. ROS2 Integration**
- URDF/Xacro robot model  
- RViz2 visualization  
- Joint State Publisher GUI  
- Ready for TF broadcasting  
- Ready for hardware bridge (Arduino or ESP32)

---

# âš™ï¸ Installation

### **Clone the repository**
```bash
git clone https://github.com/Mohammed-Shehsin/ros2-head-tracker-gimbal.git
cd ros2-head-tracker-gimbal
```

### **Python Dependencies**
Create `requirements.txt` (already included):

```
mediapipe
opencv-python
numpy
pyserial
```

Install:
```bash
pip install -r requirements.txt
```

---

# ğŸ§  Head Tracking â€“ Mathematical Model

### **Yaw (Leftâ€“Right Rotation)**
$begin:math:display$
S\_\{\\text\{yaw\}\}
\=
\\frac\{d\_R \- d\_L\}\{d\_R \+ d\_L\}
$end:math:display$

- $begin:math:text$ d\_R $end:math:text$: Horizontal distance from nose to right eye  
- $begin:math:text$ d\_L $end:math:text$: Horizontal distance from nose to left eye  
- $begin:math:text$ S\_\{\\text\{yaw\}\} \> 0 $end:math:text$ â†’ Turning Right  
- $begin:math:text$ S\_\{\\text\{yaw\}\} \< 0 $end:math:text$ â†’ Turning Left  

---

### **Pitch (Upâ€“Down Rotation)**

$begin:math:display$
S\_\{\\text\{pitch\}\}
\=
\\frac\{d\_D \- d\_U\}\{d\_D \+ d\_U\}
$end:math:display$

- $begin:math:text$ d\_U $end:math:text$: Vertical distance nose â†’ upper face region  
- $begin:math:text$ d\_D $end:math:text$: Vertical distance nose â†’ chin  
- $begin:math:text$ S\_\{\\text\{pitch\}\} \> 0 $end:math:text$ â†’ Looking Up  
- $begin:math:text$ S\_\{\\text\{pitch\}\} \< 0 $end:math:text$ â†’ Looking Down  

---

### **Roll Compensation (Head Tilt)**

$begin:math:display$
\\theta\_\{\\text\{roll\}\}
\=
\\arctan2\( y\_\{RE\} \- y\_\{LE\}\,\\\; x\_\{RE\} \- x\_\{LE\} \)
$end:math:display$

All facial points are rotated by $begin:math:text$ \-\\theta\_\{\\text\{roll\}\} $end:math:text$ to stabilize yaw/pitch output.

---

# ğŸ› ï¸ Hardware Setup

### Components Used:
- MG90S micro servos Ã—2  
- Aluminium panâ€“tilt bracket  
- Arduino Nano / ESP32  
- External 5V servo supply  
- Web camera or USB cam  
- Optional ball-head for mounting  

### Wiring:
```
Arduino D3 â†’ Servo1 (Yaw)
Arduino D5 â†’ Servo2 (Pitch)
5V External â†’ Servo Power
GND Shared between Arduino & Servos
```

---

# ğŸ“¡ Communication (Python â†’ Arduino)

### UDP Packet Format
```
<yaw_angle>,<pitch_angle>
```

Example:
```
120,80
```

### Arduino receives â†’ moves servos accordingly.

---

# ğŸ¦¾ ROS2 URDF/Xacro Model

### Package structure:
```
gimbal_description/
 â”£ urdf/
 â”ƒ â”— gimbal.urdf.xacro
 â”£ rviz/
 â”ƒ â”— display.rviz
 â”£ launch/
 â”ƒ â”— display.launch.py
 â”— package.xml
```

### Launch the model:
```bash
ros2 launch gimbal_description display.launch.py
```

To move joints:
```bash
ros2 run joint_state_publisher_gui joint_state_publisher_gui
```

---

# ğŸ§© Project Structure

```
.
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ head_tracker_udp.py
â”œâ”€â”€ arduino/
â”‚   â””â”€â”€ dual_servo_udp.ino
â”œâ”€â”€ gimbal_description/
â”‚   â”œâ”€â”€ urdf/
â”‚   â”œâ”€â”€ launch/
â”‚   â”œâ”€â”€ rviz/
â”‚   â””â”€â”€ CMakeLists.txt
â”œâ”€â”€ media/
â”‚   â””â”€â”€ demo.gif
â””â”€â”€ README.md
```

---

# ğŸ“˜ Roadmap

### âœ… Completed  
âœ” Head tracking  
âœ” Servo control  
âœ” UDP communication  
âœ” ROS2 URDF model  
âœ” RViz visualization  

### ğŸ”œ Next  
â¬œ ROS2 Hardware Interface (ros2_control)  
â¬œ TF broadcasting  
â¬œ Camera mount CAD model  
â¬œ PID-based servo smoothing  
â¬œ Gazebo simulation  

---

# ğŸ¤ Contributing  
Pull requests are welcome! Please open an issue first.

---

# ğŸ“„ License  
MIT License

---
